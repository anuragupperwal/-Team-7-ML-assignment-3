{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T12:14:46.059565Z",
          "iopub.status.busy": "2024-03-14T12:14:46.058921Z",
          "iopub.status.idle": "2024-03-14T12:14:49.551241Z",
          "shell.execute_reply": "2024-03-14T12:14:49.550297Z",
          "shell.execute_reply.started": "2024-03-14T12:14:46.059534Z"
        },
        "id": "eGwbRetNz0-k",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-14T12:14:49.554179Z",
          "iopub.status.busy": "2024-03-14T12:14:49.553410Z",
          "iopub.status.idle": "2024-03-14T12:14:49.560427Z",
          "shell.execute_reply": "2024-03-14T12:14:49.559552Z",
          "shell.execute_reply.started": "2024-03-14T12:14:49.554145Z"
        },
        "id": "sE_FifA9z0-k",
        "outputId": "b2a06bb7-6c5b-4aec-9e42-0a280a8bd67d",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T12:14:49.562431Z",
          "iopub.status.busy": "2024-03-14T12:14:49.561744Z",
          "iopub.status.idle": "2024-03-14T12:14:49.593602Z",
          "shell.execute_reply": "2024-03-14T12:14:49.592858Z",
          "shell.execute_reply.started": "2024-03-14T12:14:49.562396Z"
        },
        "id": "imWkMzncz0-l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-14T12:14:49.596805Z",
          "iopub.status.busy": "2024-03-14T12:14:49.596445Z",
          "iopub.status.idle": "2024-03-14T12:14:49.613841Z",
          "shell.execute_reply": "2024-03-14T12:14:49.613069Z",
          "shell.execute_reply.started": "2024-03-14T12:14:49.596772Z"
        },
        "id": "S5S3wfO5z0-l",
        "outputId": "c2392f94-5e1e-4be9-d9ff-bdc127021f04",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kjcSuWnRCIP-"
      },
      "outputs": [],
      "source": [
        "random_seed = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0fKEMWlPCIP-"
      },
      "outputs": [],
      "source": [
        "embedding_values = [5,10]\n",
        "context_length_values = [5,7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-14T14:13:44.505198Z",
          "iopub.status.busy": "2024-03-14T14:13:44.504821Z",
          "iopub.status.idle": "2024-03-14T14:13:44.538752Z",
          "shell.execute_reply": "2024-03-14T14:13:44.537877Z",
          "shell.execute_reply.started": "2024-03-14T14:13:44.505169Z"
        },
        "id": "CqL_6kSJz0-l",
        "outputId": "c84a2254-dd8a-43c7-e8f2-9cf42b7d293e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data = open('shakespeare2.txt', 'r').read()\n",
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-14T14:13:45.058884Z",
          "iopub.status.busy": "2024-03-14T14:13:45.058000Z",
          "iopub.status.idle": "2024-03-14T14:13:45.064564Z",
          "shell.execute_reply": "2024-03-14T14:13:45.063618Z",
          "shell.execute_reply.started": "2024-03-14T14:13:45.058851Z"
        },
        "id": "-V8CbeEvz0-l",
        "outputId": "82dd6163-7b2e-4d5a-f05d-90c96eaab9e8",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citi'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-14T14:13:45.869852Z",
          "iopub.status.busy": "2024-03-14T14:13:45.869517Z",
          "iopub.status.idle": "2024-03-14T14:13:45.936767Z",
          "shell.execute_reply": "2024-03-14T14:13:45.935686Z",
          "shell.execute_reply.started": "2024-03-14T14:13:45.869825Z"
        },
        "id": "5enHPwCRz0-m",
        "outputId": "0eca2942-cb9a-4e04-f582-a5bf0156fb0b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: '\\n',\n",
              "  1: ' ',\n",
              "  2: '!',\n",
              "  3: '$',\n",
              "  4: '&',\n",
              "  5: \"'\",\n",
              "  6: ',',\n",
              "  7: '-',\n",
              "  8: '.',\n",
              "  9: '3',\n",
              "  10: ':',\n",
              "  11: ';',\n",
              "  12: '?',\n",
              "  13: 'A',\n",
              "  14: 'B',\n",
              "  15: 'C',\n",
              "  16: 'D',\n",
              "  17: 'E',\n",
              "  18: 'F',\n",
              "  19: 'G',\n",
              "  20: 'H',\n",
              "  21: 'I',\n",
              "  22: 'J',\n",
              "  23: 'K',\n",
              "  24: 'L',\n",
              "  25: 'M',\n",
              "  26: 'N',\n",
              "  27: 'O',\n",
              "  28: 'P',\n",
              "  29: 'Q',\n",
              "  30: 'R',\n",
              "  31: 'S',\n",
              "  32: 'T',\n",
              "  33: 'U',\n",
              "  34: 'V',\n",
              "  35: 'W',\n",
              "  36: 'X',\n",
              "  37: 'Y',\n",
              "  38: 'Z',\n",
              "  39: 'a',\n",
              "  40: 'b',\n",
              "  41: 'c',\n",
              "  42: 'd',\n",
              "  43: 'e',\n",
              "  44: 'f',\n",
              "  45: 'g',\n",
              "  46: 'h',\n",
              "  47: 'i',\n",
              "  48: 'j',\n",
              "  49: 'k',\n",
              "  50: 'l',\n",
              "  51: 'm',\n",
              "  52: 'n',\n",
              "  53: 'o',\n",
              "  54: 'p',\n",
              "  55: 'q',\n",
              "  56: 'r',\n",
              "  57: 's',\n",
              "  58: 't',\n",
              "  59: 'u',\n",
              "  60: 'v',\n",
              "  61: 'w',\n",
              "  62: 'x',\n",
              "  63: 'y',\n",
              "  64: 'z'},\n",
              " {'\\n': 0,\n",
              "  ' ': 1,\n",
              "  '!': 2,\n",
              "  '$': 3,\n",
              "  '&': 4,\n",
              "  \"'\": 5,\n",
              "  ',': 6,\n",
              "  '-': 7,\n",
              "  '.': 8,\n",
              "  '3': 9,\n",
              "  ':': 10,\n",
              "  ';': 11,\n",
              "  '?': 12,\n",
              "  'A': 13,\n",
              "  'B': 14,\n",
              "  'C': 15,\n",
              "  'D': 16,\n",
              "  'E': 17,\n",
              "  'F': 18,\n",
              "  'G': 19,\n",
              "  'H': 20,\n",
              "  'I': 21,\n",
              "  'J': 22,\n",
              "  'K': 23,\n",
              "  'L': 24,\n",
              "  'M': 25,\n",
              "  'N': 26,\n",
              "  'O': 27,\n",
              "  'P': 28,\n",
              "  'Q': 29,\n",
              "  'R': 30,\n",
              "  'S': 31,\n",
              "  'T': 32,\n",
              "  'U': 33,\n",
              "  'V': 34,\n",
              "  'W': 35,\n",
              "  'X': 36,\n",
              "  'Y': 37,\n",
              "  'Z': 38,\n",
              "  'a': 39,\n",
              "  'b': 40,\n",
              "  'c': 41,\n",
              "  'd': 42,\n",
              "  'e': 43,\n",
              "  'f': 44,\n",
              "  'g': 45,\n",
              "  'h': 46,\n",
              "  'i': 47,\n",
              "  'j': 48,\n",
              "  'k': 49,\n",
              "  'l': 50,\n",
              "  'm': 51,\n",
              "  'n': 52,\n",
              "  'o': 53,\n",
              "  'p': 54,\n",
              "  'q': 55,\n",
              "  'r': 56,\n",
              "  's': 57,\n",
              "  't': 58,\n",
              "  'u': 59,\n",
              "  'v': 60,\n",
              "  'w': 61,\n",
              "  'x': 62,\n",
              "  'y': 63,\n",
              "  'z': 64})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "unique_chars = list(set(''.join(data)))\n",
        "unique_chars.sort()\n",
        "to_string = {i:ch for i, ch in enumerate(unique_chars)}\n",
        "to_int = {ch:i for i, ch in enumerate(unique_chars)}\n",
        "to_string, to_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T14:13:46.399145Z",
          "iopub.status.busy": "2024-03-14T14:13:46.398063Z",
          "iopub.status.idle": "2024-03-14T14:13:53.708608Z",
          "shell.execute_reply": "2024-03-14T14:13:53.707817Z",
          "shell.execute_reply.started": "2024-03-14T14:13:46.399103Z"
        },
        "id": "H7mCrVJhz0-m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_tensors(block_size):\n",
        "    X, Y = [], []\n",
        "    for i in range(0, len(data)-block_size, 1):\n",
        "        X.append([to_int[ch] for ch in data[i:i+block_size]])\n",
        "        Y.append(to_int[data[i+block_size]])\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "    return X,Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjgAkDN5CIP_",
        "outputId": "cb3bb7ea-a987-409e-96c9-29f07c318bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 torch.Size([1115389, 5]) torch.Size([1115389])\n",
            "7 torch.Size([1115387, 7]) torch.Size([1115387])\n"
          ]
        }
      ],
      "source": [
        "tensors_dict = {}\n",
        "for context_length in context_length_values:\n",
        "    tensors_dict[context_length] = get_tensors(context_length)\n",
        "    print(context_length, tensors_dict[context_length][0].shape, tensors_dict[context_length][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yufskQj7CIQA",
        "outputId": "2bc532ce-f095-46b4-c718-89bd74e5fd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 torch.Size([65, 5])\n",
            "10 torch.Size([65, 10])\n"
          ]
        }
      ],
      "source": [
        "embedding_dict = {}\n",
        "for embedding in embedding_values:\n",
        "    embedding_dict[embedding] = nn.Embedding(len(to_string), embedding)\n",
        "    print(embedding, embedding_dict[embedding].weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jlcvNS_1z0-m"
      },
      "outputs": [],
      "source": [
        "class NextChar(nn.Module):\n",
        "  def __init__(self, block_size, vocab_size, emb_dim, hidden_dims):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.lin1 = nn.Linear(block_size * emb_dim, hidden_dims[0])\n",
        "    self.lin2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "    self.lin3 = nn.Linear(hidden_dims[1], vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = torch.sin(self.lin1(x))\n",
        "    x = torch.sin(self.lin2(x))\n",
        "    x = self.lin3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HbjIF9oeCIQB"
      },
      "outputs": [],
      "source": [
        "model_dict = {}\n",
        "for context_length in context_length_values:\n",
        "    for embedding in embedding_values:\n",
        "        model_dict[(context_length, embedding)] = NextChar(context_length, len(to_string), embedding, [64, 64])\n",
        "        model_dict[(context_length, embedding)].to(device)\n",
        "        # print(context_length, embedding, model_dict[(context_length, embedding)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57Y5Ao8_z0-m"
      },
      "outputs": [],
      "source": [
        "# Generate names from untrained model\n",
        "g = torch.Generator()\n",
        "g.manual_seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "def generate_name(model,sentence, itos, stoi, block_size, max_len=10):\n",
        "    original_sentence = sentence\n",
        "    if len(sentence) < block_size:\n",
        "        sentence = \" \" * (block_size - len(sentence)) + sentence\n",
        "    using_for_predicction = sentence[-block_size:].lower()\n",
        "    context = [stoi[word] for word in using_for_predicction]\n",
        "    prediction = \"\"\n",
        "    for i in range(max_len):\n",
        "        x = torch.tensor(context).view(1, -1).to(device)\n",
        "        y_pred = model(x)\n",
        "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
        "        ch = itos[ix]\n",
        "        prediction += ch\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "    return original_sentence + prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFDxLhnQz0-n",
        "outputId": "c0eb2b8f-9596-436c-f39d-b290bc142b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_length = 5, dimension = 5,epoch = 0, loss = 2.023308515548706\n",
            "context_length = 5, dimension = 5,epoch = 100, loss = 1.697106957435608\n",
            "context_length = 5, dimension = 10,epoch = 0, loss = 1.9821012020111084\n",
            "context_length = 5, dimension = 10,epoch = 100, loss = 1.6859607696533203\n",
            "context_length = 7, dimension = 5,epoch = 0, loss = 2.0991861820220947\n",
            "context_length = 7, dimension = 5,epoch = 100, loss = 1.7360596656799316\n",
            "context_length = 7, dimension = 10,epoch = 0, loss = 1.9347500801086426\n",
            "context_length = 7, dimension = 10,epoch = 100, loss = 1.6435843706130981\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "for context_length in context_length_values:\n",
        "    for embedding in embedding_values:\n",
        "        model = model_dict[(context_length, embedding)]\n",
        "        X, Y = tensors_dict[context_length]\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "        import time\n",
        "        # Mini-batch training\n",
        "        batch_size = 4096\n",
        "        print_every = 100\n",
        "        elapsed_time = []\n",
        "        for epoch in range(200):\n",
        "            start_time = time.time()\n",
        "            for i in range(0, X.shape[0], batch_size):\n",
        "                x = X[i:i+batch_size].to(device)\n",
        "                y = Y[i:i+batch_size].to(device)\n",
        "                y_pred = model(x)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "            end_time = time.time()\n",
        "            elapsed_time.append(end_time - start_time)\n",
        "            if epoch % print_every == 0:\n",
        "                print(f\"context_length = {context_length}, dimension = {embedding},epoch = {epoch}, loss = {loss.item()}\")\n",
        "\n",
        "        # saving model weights\n",
        "        model = model.to('cpu')\n",
        "\n",
        "# Save the trained model\n",
        "        torch.save(model.state_dict(), f\"context_{context_length}_embedding_{embedding}.pth\")\n",
        "        # torch.save(model.state_dict(), f\"{random_seed}_context_{context_length}_embedding_{embedding}.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgbZSHluz0-n"
      },
      "source": [
        "Tuning knobs\n",
        "\n",
        "1. Embedding size\n",
        "2. MLP\n",
        "3. Context length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09VsDfUuCIQD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4597790,
          "sourceId": 7842379,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}